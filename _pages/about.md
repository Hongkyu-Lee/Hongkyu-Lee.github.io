---
layout: about
title: About
permalink: /
subtitle: <a href='mailto:hong.kyu.lee@emory.edu'>hong.kyu.lee@emory.edu</a> | <a href='https://www.cs.emory.edu/site/aims/'>Emory AIMS</a>

profile:
  align: right # right or left
  image: grey2.png
  image_circular: false # crops the image to make it circular
  more_info: >

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

<!-- Write your biography here. Tell the world abbbbb yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any of these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](https://fontawesome.com/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->

I am a PhD candidate at Emory University. I am a member of [AIMS Lab](https://www.cs.emory.edu/site/aims/), under the supervision of [Prof. Li Xiong](https://www.cs.emory.edu/~lxiong/) and [Prof. Carl Yang](https://www.cs.emory.edu/~jyang71/). My research is dedicated to advancing the Privacy and Security of AI and develop Trustworthy AI models. My primary focus is on data privacy and the security of machine learning models. My projects involve developing robust machine unlearning mechanisms and differentially private training, and probing model vulnerabilities through membership inference attacks. I have experience implementing these methods on complex architectures, including large language models (LLMs), vision transformers, and multimodal models.

A central question driving my work is how to precisely define the "learned state" of a model. I believe that a deeper understanding of this concept is essential for accurately assessing privacy risks and, consequently, for building systems that can truly and verifiably "unlearn" information.

<br>
<br>
